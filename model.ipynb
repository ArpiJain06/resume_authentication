{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o_UwxednejRx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZtBR1E05dSu",
        "outputId": "17435dae-a2c4-43c4-c3d3-354750ce4138"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and Explore the Data\n",
        "def load_and_preprocess_data(data_dir, label,  augmentation):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(data_dir):\n",
        "        img_path = os.path.join(data_dir, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (256, 256))\n",
        "        img = img / 255.0\n",
        "        data.append(img)\n",
        "        labels.append(label)\n",
        "\n",
        "    data = np.array(data)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    if augmentation:\n",
        "        datagen = ImageDataGenerator(\n",
        "            rotation_range=20,\n",
        "            width_shift_range=0.2,\n",
        "            height_shift_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            shear_range=0.2,\n",
        "            horizontal_flip=True,\n",
        "            vertical_flip=True\n",
        "        )\n",
        "        datagen.fit(data)\n",
        "        augmented_data = datagen.flow(data, labels, batch_size=len(data), shuffle=False).next()\n",
        "        data, labels = augmented_data[0], labels\n",
        "\n",
        "    return data, labels"
      ],
      "metadata": {
        "id": "yxbti7B95UA9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resume_folder = '/content/drive/MyDrive/resumes'\n",
        "non_resume_folder = '/content/drive/MyDrive/not_resumes'"
      ],
      "metadata": {
        "id": "lMk_Zx1i5UDu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data from the two folders\n",
        "resume_data_aug, resume_labels_aug = load_and_preprocess_data(resume_folder, 1, True)\n",
        "non_resume_data_aug, non_resume_labels_aug = load_and_preprocess_data(non_resume_folder, 0, True)\n",
        "\n",
        "resume_data, resume_labels = load_and_preprocess_data(resume_folder, 1, False)\n",
        "non_resume_data, non_resume_labels = load_and_preprocess_data(non_resume_folder, 0, False)"
      ],
      "metadata": {
        "id": "WnB2GO9z5UGO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine data and labels\n",
        "X_train_aug = np.concatenate((resume_data_aug, non_resume_data_aug), axis=0)\n",
        "y_train_aug = np.concatenate((resume_labels_aug, non_resume_labels_aug), axis=0)\n",
        "\n",
        "X_train = np.concatenate((resume_data, non_resume_data), axis=0)\n",
        "y_train = np.concatenate((resume_labels, non_resume_labels), axis=0)"
      ],
      "metadata": {
        "id": "5SQpnMjf5UI4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the data\n",
        "augmented_data = list(zip(X_train_aug, y_train_aug))\n",
        "np.random.shuffle(augmented_data)\n",
        "X_train_aug, y_train_aug = zip(*augmented_data)\n",
        "X_train_aug = np.array(X_train_aug)\n",
        "y_train_aug = np.array(y_train_aug)\n",
        "\n",
        "y_train_aug = to_categorical(y_train_aug, num_classes=2)\n",
        "y_train = to_categorical(y_train, num_classes=2)\n",
        "\n",
        "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(\n",
        "    X_train_aug, y_train_aug, test_size=0.3, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "A6jGMM935UL9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "model=keras.models.Sequential([\n",
        "    keras.layers.Conv2D(filters=128, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(256,256,3)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3)),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(1024,activation='relu'),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(1024,activation='relu'),\n",
        "    keras.layers.Dropout(0.8),\n",
        "    keras.layers.Dense(2,activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "spHb5Sji5UOi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwBx8aUy5URg",
        "outputId": "06f2d933-22f1-4e1b-c941-cd19bd76ba99"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 128)       46592     \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 62, 62, 128)       512       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 31, 31, 128)       0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 31, 31, 256)       819456    \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 31, 31, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 10, 10, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 10, 10, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 10, 10, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 10, 10, 256)       65792     \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 10, 10, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 10, 10, 256)       65792     \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 10, 10, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 5, 5, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6400)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              6554624   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 2050      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9198594 (35.09 MB)\n",
            "Trainable params: 9196290 (35.08 MB)\n",
            "Non-trainable params: 2304 (9.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"X_train_split shape:\", X_train_split.shape)\n",
        "print(\"y_train_split shape:\", y_train_split.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQFhBn-p5UUc",
        "outputId": "4389f31d-97ec-4e75-9bd1-d968cf28fd71"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_split shape: (70, 256, 256, 3)\n",
            "y_train_split shape: (70, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_split, y_train_split, epochs=5, validation_data=(X_test_split, y_test_split))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L31RGHN5UXm",
        "outputId": "3dac3709-848c-4c0d-afd9-668fd43c77a0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3/3 [==============================] - 18s 5s/step - loss: 1.9187 - accuracy: 0.7714 - val_loss: 5.7803 - val_accuracy: 0.4667\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 17s 4s/step - loss: 0.7302 - accuracy: 0.8571 - val_loss: 16.6467 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 13s 3s/step - loss: 0.8295 - accuracy: 0.8429 - val_loss: 20.2421 - val_accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 13s 4s/step - loss: 0.5252 - accuracy: 0.8714 - val_loss: 11.5685 - val_accuracy: 0.4000\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 11s 3s/step - loss: 1.0549 - accuracy: 0.7714 - val_loss: 15.2309 - val_accuracy: 0.4333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test_split, y_test_split)\n",
        "test_accuracy_percentage = accuracy * 100\n",
        "print(f'Test Accuracy: {test_accuracy_percentage:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfVdaKx45Uad",
        "outputId": "0f958317-b97b-4a27-8829-844b8966c22a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step - loss: 15.2309 - accuracy: 0.4333\n",
            "Test Accuracy: 43.33%\n"
          ]
        }
      ]
    }
  ]
}