{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import MobileNetV2\n",
        "from keras.optimizers import Adam\n",
        "from keras import Input"
      ],
      "metadata": {
        "id": "wsv33dss2b74"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resume_folder = '/content/drive/MyDrive/resumes'\n",
        "non_resume_folder = '/content/drive/MyDrive/not_resumes'"
      ],
      "metadata": {
        "id": "0GMplsFN50zq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and Explore the Data\n",
        "def load_and_preprocess_data(data_dir, label, augmentation):\n",
        "    data = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(data_dir):\n",
        "        img_path = os.path.join(data_dir, filename)\n",
        "\n",
        "        # Check if the file exists and is a valid image\n",
        "        if os.path.isfile(img_path):\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            # Check if the image is successfully loaded\n",
        "            if img is not None:\n",
        "                img = cv2.resize(img, (128, 128))\n",
        "                img = img / 255.0\n",
        "                data.append(img)\n",
        "                labels.append(label)\n",
        "\n",
        "    data = np.array(data)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    if augmentation:\n",
        "        datagen = ImageDataGenerator(\n",
        "            rotation_range=20,\n",
        "            width_shift_range=0.2,\n",
        "            height_shift_range=0.2,\n",
        "            zoom_range=0.1,\n",
        "            shear_range=0.2,\n",
        "            horizontal_flip=True\n",
        "        )\n",
        "        datagen.fit(data)\n",
        "        augmented_data = datagen.flow(data, labels, batch_size=len(data), shuffle=False).next()\n",
        "        data, labels = augmented_data[0], labels\n",
        "\n",
        "    return data, labels"
      ],
      "metadata": {
        "id": "uFlq-ztV2cA1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data from the two folders\n",
        "resume_data_aug, resume_labels_aug = load_and_preprocess_data(resume_folder, 1, True)\n",
        "non_resume_data_aug, non_resume_labels_aug = load_and_preprocess_data(non_resume_folder, 0, True)\n",
        "\n",
        "resume_data, resume_labels = load_and_preprocess_data(resume_folder, 1, False)\n",
        "non_resume_data, non_resume_labels = load_and_preprocess_data(non_resume_folder, 0, False)"
      ],
      "metadata": {
        "id": "VpOcE4wr2cEp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine data and labels\n",
        "X_train_aug = np.concatenate((resume_data_aug, non_resume_data_aug), axis=0)\n",
        "y_train_aug = np.concatenate((resume_labels_aug, non_resume_labels_aug), axis=0)\n",
        "\n",
        "X_train = np.concatenate((resume_data, non_resume_data), axis=0)\n",
        "y_train = np.concatenate((resume_labels, non_resume_labels), axis=0)"
      ],
      "metadata": {
        "id": "DFk9BUKm5YU_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the data\n",
        "augmented_data = list(zip(X_train_aug, y_train_aug))\n",
        "np.random.shuffle(augmented_data)\n",
        "X_train_aug, y_train_aug = zip(*augmented_data)\n",
        "X_train_aug = np.array(X_train_aug)\n",
        "y_train_aug = np.array(y_train_aug)"
      ],
      "metadata": {
        "id": "1RGwPvZe5Y04"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(\n",
        "    X_train_aug, y_train_aug, test_size=0.2, random_state=42 , stratify=y_train_aug\n",
        ")"
      ],
      "metadata": {
        "id": "E8xzxKsagmXN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'y_train' is your training labels\n",
        "class_distribution = pd.Series(y_train.flatten()).value_counts()\n",
        "print(\"Class Distribution:\")\n",
        "print(class_distribution)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdxXDmhG62It",
        "outputId": "16df195e-e7ac-4d35-f76d-67dd9185bf4f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution:\n",
            "1    117\n",
            "0    117\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=Input(shape=(128, 128, 3)))\n",
        "\n",
        "# Freeze the convolutional layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom classification layers\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1jaoSxiXJwK",
        "outputId": "5d90a17d-858d-4219-a079-b2aa3afde498"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the final model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N661gKBrXJz8",
        "outputId": "12e38091-d617-43f2-c67f-0c30a97a6c47"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "history = model.fit(X_train_split, y_train_split, batch_size=batch_size, epochs=epochs, validation_data=(X_test_split, y_test_split))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test_split, y_test_split, batch_size=batch_size)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4AR24VXXJ2M",
        "outputId": "8dedef2d-0753-428c-801c-e7ee49708146"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 9s 805ms/step - loss: 0.4707 - accuracy: 0.7807 - val_loss: 0.4147 - val_accuracy: 0.8085\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 2s 433ms/step - loss: 0.2073 - accuracy: 0.9091 - val_loss: 0.2772 - val_accuracy: 0.8723\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 2s 429ms/step - loss: 0.1131 - accuracy: 0.9733 - val_loss: 0.2324 - val_accuracy: 0.8936\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 2s 432ms/step - loss: 0.0746 - accuracy: 0.9679 - val_loss: 0.2242 - val_accuracy: 0.9149\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 4s 808ms/step - loss: 0.0463 - accuracy: 0.9947 - val_loss: 0.2095 - val_accuracy: 0.9149\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 3s 512ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9149\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 2s 390ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9149\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 2s 437ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9362\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 3s 443ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.8936\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.9149\n",
            "2/2 [==============================] - 0s 146ms/step - loss: 0.2529 - accuracy: 0.9149\n",
            "Test Loss: 0.2529\n",
            "Test Accuracy: 91.49%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss, cohen_kappa_score, roc_auc_score\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = model.predict(X_test_split)\n",
        "\n",
        "# Thresholds\n",
        "thresholds = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "\n",
        "for threshold in thresholds:\n",
        "    y_pred_binary = (y_pred > threshold).astype(int)\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision = precision_score(y_test_split, y_pred_binary)\n",
        "    recall = recall_score(y_test_split, y_pred_binary)\n",
        "    f1 = f1_score(y_test_split, y_pred_binary)\n",
        "    logloss = log_loss(y_test_split, y_pred_binary)\n",
        "    kappa = cohen_kappa_score(y_test_split, y_pred_binary)\n",
        "\n",
        "    # ROC-AUC requires binary or multilabel indicator format\n",
        "    roc_auc = roc_auc_score(y_test_split, y_pred_binary)\n",
        "\n",
        "    print(f\"Threshold: {threshold}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Log Loss: {logloss:.4f}, Cohen's Kappa: {kappa:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
        "\n",
        "# Choose an appropriate threshold, e.g., 0.5\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "precision = precision_score(y_test_split, y_pred_binary)\n",
        "recall = recall_score(y_test_split, y_pred_binary)\n",
        "f1 = f1_score(y_test_split, y_pred_binary)\n",
        "logloss = log_loss(y_test_split, y_pred_binary)\n",
        "kappa = cohen_kappa_score(y_test_split, y_pred_binary)\n",
        "roc_auc = roc_auc_score(y_test_split, y_pred_binary)\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_split, y_pred_binary)\n",
        "\n",
        "print(\"\\nOverall Metrics:\")\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Log Loss:\", logloss)\n",
        "print(\"Cohen's Kappa:\", kappa)\n",
        "print(\"ROC-AUC:\", roc_auc)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__AhJuiRcMmR",
        "outputId": "c11fad9f-4b90-4f4f-ab04-4234e5cbf9bf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 2s 216ms/step\n",
            "Threshold: 0.2, Precision: 0.8148, Recall: 0.9565, F1: 0.8800, Log Loss: 4.6013, Cohen's Kappa: 0.7455, ROC-AUC: 0.8741\n",
            "Threshold: 0.3, Precision: 0.8462, Recall: 0.9565, F1: 0.8980, Log Loss: 3.8344, Cohen's Kappa: 0.7877, ROC-AUC: 0.8949\n",
            "Threshold: 0.4, Precision: 0.8462, Recall: 0.9565, F1: 0.8980, Log Loss: 3.8344, Cohen's Kappa: 0.7877, ROC-AUC: 0.8949\n",
            "Threshold: 0.5, Precision: 0.8800, Recall: 0.9565, F1: 0.9167, Log Loss: 3.0675, Cohen's Kappa: 0.8300, ROC-AUC: 0.9158\n",
            "Threshold: 0.6, Precision: 0.9167, Recall: 0.9565, F1: 0.9362, Log Loss: 2.3007, Cohen's Kappa: 0.8724, ROC-AUC: 0.9366\n",
            "\n",
            "Overall Metrics:\n",
            "Precision: 0.88\n",
            "Recall: 0.9565217391304348\n",
            "F1 Score: 0.9166666666666666\n",
            "Log Loss: 3.0675449692865664\n",
            "Cohen's Kappa: 0.8300180831826401\n",
            "ROC-AUC: 0.9157608695652174\n",
            "\n",
            "Confusion Matrix:\n",
            "[[21  3]\n",
            " [ 1 22]]\n"
          ]
        }
      ]
    }
  ]
}